# å®‰è£…æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» Tranvideo çš„å„ç§å®‰è£…æ–¹å¼ï¼ŒåŒ…æ‹¬ Dockerã€æºç éƒ¨ç½²å’Œå¼€å‘ç¯å¢ƒæ­å»ºã€‚

## ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®

| ç»„ä»¶ | è¦æ±‚ |
|------|------|
| CPU | 4 æ ¸å¿ƒ |
| å†…å­˜ | 8GB RAM |
| GPU | NVIDIA GPU with 8GB VRAM |
| å­˜å‚¨ | 32GB å¯ç”¨ç©ºé—´ |
| æ“ä½œç³»ç»Ÿ | Linux / Windows / macOS |

### æ¨èé…ç½®

| ç»„ä»¶ | æ¨è |
|------|------|
| CPU | 8 æ ¸å¿ƒä»¥ä¸Š |
| å†…å­˜ | 16GB RAM |
| GPU | NVIDIA RTX 4070 æˆ–æ›´é«˜ |
| å­˜å‚¨ | 64GB+ SSD |
| æ“ä½œç³»ç»Ÿ | Ubuntu 20.04+ / Debian 11+ |

### è½¯ä»¶ä¾èµ–

#### é€šç”¨ä¾èµ–

- Docker 20.10+
- Docker Compose 2.0+
- NVIDIA Container Runtime
- CUDA 11.0+

#### æºç éƒ¨ç½²é¢å¤–ä¾èµ–

- Python 3.8+
- FFmpeg 4.0+
- Git

---

## æ–¹å¼ä¸€ï¼šDocker Composeï¼ˆæ¨èï¼‰

è¿™æ˜¯æœ€ç®€å•ä¸”æ¨èçš„éƒ¨ç½²æ–¹å¼ï¼ŒåŒ…å« Ollama æœåŠ¡å’Œè‡ªåŠ¨æ¨¡å‹ä¸‹è½½ã€‚

### 1. å®‰è£… Docker å’Œ Docker Compose

#### Ubuntu/Debian

```bash
# å¸è½½æ—§ç‰ˆæœ¬
sudo apt-get remove docker docker-engine docker.io containerd runc

# å®‰è£…ä¾èµ–
sudo apt-get update
sudo apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# æ·»åŠ  Docker GPG å¯†é’¥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# æ·»åŠ  Docker ä»“åº“
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# å®‰è£… Docker
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin
```

#### CentOS/RHEL

```bash
# å¸è½½æ—§ç‰ˆæœ¬
sudo yum remove docker docker-client docker-client-latest docker-common

# å®‰è£…ä¾èµ–
sudo yum install -y yum-utils

# æ·»åŠ  Docker ä»“åº“
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# å®‰è£… Docker
sudo yum install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# å¯åŠ¨ Docker
sudo systemctl start docker
sudo systemctl enable docker
```

#### Windows

1. ä¸‹è½½ [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop)
2. å®‰è£…å¹¶é‡å¯ç³»ç»Ÿ
3. å¯ç”¨ WSL 2 åç«¯

#### macOS

1. ä¸‹è½½ [Docker Desktop for Mac](https://www.docker.com/products/docker-desktop)
2. å®‰è£…å¹¶å¯åŠ¨ Docker Desktop

### 2. å®‰è£… NVIDIA Container Runtime

```bash
# æ·»åŠ  NVIDIA Container Runtime ä»“åº“
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# æ›´æ–°å¹¶å®‰è£…
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# é‡å¯ Docker
sudo systemctl restart docker
```

### 3. éªŒè¯ GPU æ”¯æŒ

```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æµ‹è¯• Docker GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```

### 4. ä¸‹è½½ docker-compose.yaml

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p tranvideo && cd tranvideo

# ä¸‹è½½é…ç½®æ–‡ä»¶
wget https://raw.githubusercontent.com/MitaHill/tranvideo/main/docker-compose.yaml

# æˆ–ä½¿ç”¨ curl
curl -o docker-compose.yaml https://raw.githubusercontent.com/MitaHill/tranvideo/main/docker-compose.yaml
```

### 5. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose up -d

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
docker compose logs -f tranvideo
```

### 6. ç­‰å¾…æ¨¡å‹ä¸‹è½½

é¦–æ¬¡å¯åŠ¨ä¼šè‡ªåŠ¨ä¸‹è½½ Ollama æ¨¡å‹ï¼ˆçº¦ 4.5GBï¼‰ï¼Œéœ€è¦ 3-10 åˆ†é’Ÿï¼š

```bash
# ç›‘æ§æ¨¡å‹ä¸‹è½½è¿›åº¦
docker compose logs -f ollama-setup
```

### 7. éªŒè¯éƒ¨ç½²

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker compose ps

# æ£€æŸ¥ Whisper æœåŠ¡
curl http://localhost:5000/api/whisper/health

# æ£€æŸ¥é…ç½®
curl http://localhost:5000/api/tranpy/config
```

### 8. è®¿é—® Web ç•Œé¢

æ‰“å¼€æµè§ˆå™¨è®¿é—®: `http://localhost:5000`

---

## æ–¹å¼äºŒï¼šDocker å•å®¹å™¨

é€‚åˆå·²æœ‰ Ollama æœåŠ¡æˆ–æƒ³è¦ç‹¬ç«‹éƒ¨ç½²çš„åœºæ™¯ã€‚

### 1. ç¡®ä¿ NVIDIA Docker æ”¯æŒ

```bash
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```

### 2. è¿è¡Œå®¹å™¨

```bash
docker run -d \
  --name tranvideo \
  --gpus all \
  --network host \
  --restart always \
  -p 5000:5000 \
  -v $(pwd)/cache:/root/tranvideo/cache \
  kindmitaishere/tranvideo:0.6.0
```

### 3. å•ç‹¬éƒ¨ç½² Ollama

```bash
# å¯åŠ¨ Ollama
docker run -d \
  --name ollama \
  --gpus all \
  -p 11434:11434 \
  -v ollama_data:/root/.ollama \
  ollama/ollama:latest

# æ‹‰å–æ¨¡å‹
docker exec -it ollama ollama pull qwen3:8b
```

### 4. é…ç½® Ollama API

```bash
# é…ç½® API åœ°å€
curl http://localhost:5000/api/tranpy/config-ollama-api/127.0.0.1:11434

# é…ç½®æ¨¡å‹
curl http://localhost:5000/api/tranpy/config-ollama-model/qwen3:8b
```

---

## æ–¹å¼ä¸‰ï¼šæºç éƒ¨ç½²

é€‚åˆå¼€å‘è€…æˆ–éœ€è¦è‡ªå®šä¹‰çš„åœºæ™¯ã€‚

### 1. å®‰è£…ç³»ç»Ÿä¾èµ–

#### Ubuntu/Debian

```bash
sudo apt-get update
sudo apt-get install -y \
  python3.8 \
  python3-pip \
  python3-venv \
  ffmpeg \
  git \
  build-essential
```

#### CentOS/RHEL

```bash
sudo yum install -y \
  python38 \
  python38-pip \
  ffmpeg \
  git \
  gcc \
  gcc-c++
```

#### macOS

```bash
# å®‰è£… Homebrew
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# å®‰è£…ä¾èµ–
brew install python@3.9 ffmpeg git
```

#### Windows

1. å®‰è£… [Python 3.8+](https://www.python.org/downloads/)
2. å®‰è£… [FFmpeg](https://ffmpeg.org/download.html)
3. å®‰è£… [Git](https://git-scm.com/download/win)

### 2. å…‹éš†ä»“åº“

```bash
git clone https://github.com/MitaHill/tranvideo.git
cd tranvideo
```

### 3. ä¸‹è½½ Whisper æ¨¡å‹

#### æ–¹å¼ Aï¼šä½¿ç”¨ wgetï¼ˆæ¨èï¼‰

```bash
mkdir -p whisper
cd whisper

# ä» Hugging Face ä¸‹è½½
wget https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/large-v3-turbo.pt \
  -O large-v3-turbo.pt

cd ..
```

#### æ–¹å¼ Bï¼šä½¿ç”¨ Python è„šæœ¬

```bash
mkdir -p whisper

python3 << 'EOF'
import urllib.request
import os

url = "https://openaipublic.azureedge.net/main/whisper/models/large-v3-turbo.pt"
output = "whisper/large-v3-turbo.pt"

print("å¼€å§‹ä¸‹è½½ Whisper æ¨¡å‹...")
urllib.request.urlretrieve(url, output)
print(f"ä¸‹è½½å®Œæˆ: {output}")
print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(output) / 1024 / 1024:.2f} MB")
EOF
```

#### æ–¹å¼ Cï¼šæ‰‹åŠ¨ä¸‹è½½

1. è®¿é—® [Hugging Face](https://huggingface.co/openai/whisper-large-v3-turbo)
2. ä¸‹è½½ `large-v3-turbo.pt` æ–‡ä»¶
3. æ”¾ç½®åˆ°é¡¹ç›®çš„ `whisper/` ç›®å½•ä¸‹

### 4. éªŒè¯æ¨¡å‹æ–‡ä»¶

```bash
ls -lh whisper/large-v3-turbo.pt
# åº”æ˜¾ç¤ºçº¦ 1.5GB çš„æ–‡ä»¶
```

### 5. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Linux/macOS:
source venv/bin/activate

# Windows:
venv\Scripts\activate
```

### 6. å®‰è£… Python ä¾èµ–

```bash
# å‡çº§ pip
pip install --upgrade pip

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 7. é…ç½®ç¯å¢ƒ

åˆ›å»ºæˆ–ç¼–è¾‘ `config/tran-py.json`ï¼š

```json
{
  "translator_type": "ollama",
  "ollama_api": "http://127.0.0.1:11434",
  "ollama_model": "qwen3:8b",
  "openai_base_url": "https://api.openai.com/v1",
  "openai_api_key": "your-api-key-here",
  "openai_model": "gpt-3.5-turbo"
}
```

### 8. å®‰è£…å’Œé…ç½® Ollama

#### å®‰è£… Ollama

```bash
# Linux
curl https://ollama.ai/install.sh | sh

# macOS
brew install ollama

# Windows
# ä¸‹è½½å¹¶å®‰è£…: https://ollama.ai/download/windows
```

#### æ‹‰å–æ¨¡å‹

```bash
ollama pull qwen3:8b
```

#### å¯åŠ¨ Ollama æœåŠ¡

```bash
# Linux/macOS (åå°è¿è¡Œ)
ollama serve &

# Windows
# Ollama ä¼šä½œä¸ºæœåŠ¡è‡ªåŠ¨å¯åŠ¨
```

### 9. å¯åŠ¨ Tranvideo

```bash
# ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
source venv/bin/activate  # Linux/macOS
# æˆ– venv\Scripts\activate  # Windows

# å¯åŠ¨æœåŠ¡
python main.py
```

### 10. éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥æœåŠ¡
curl http://localhost:5000/api/whisper/health

# è®¿é—® Web ç•Œé¢
# æ‰“å¼€æµè§ˆå™¨: http://localhost:5000
```

---

## ç¯å¢ƒå˜é‡é…ç½®

### Docker ç¯å¢ƒå˜é‡

å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é»˜è®¤é…ç½®ï¼š

```yaml
# docker-compose.yaml
services:
  tranvideo:
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - TRANSLATOR_TYPE=ollama
      - OLLAMA_MODEL=qwen3:8b
      - LOG_LEVEL=INFO
```

### æºç éƒ¨ç½²ç¯å¢ƒå˜é‡

```bash
# åˆ›å»º .env æ–‡ä»¶
cat > .env << 'EOF'
OLLAMA_HOST=http://127.0.0.1:11434
TRANSLATOR_TYPE=ollama
OLLAMA_MODEL=qwen3:8b
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=your-api-key
LOG_LEVEL=INFO
EOF

# åŠ è½½ç¯å¢ƒå˜é‡
source .env  # Linux/macOS
# æˆ–åœ¨ Windows æ‰‹åŠ¨è®¾ç½®
```

---

## ç›®å½•ç»“æ„

### Docker éƒ¨ç½²

```
tranvideo/
â”œâ”€â”€ docker-compose.yaml    # Docker Compose é…ç½®
â””â”€â”€ cache/                 # æŒä¹…åŒ–æ•°æ®ç›®å½•
    â”œâ”€â”€ uploads/           # ä¸Šä¼ æ–‡ä»¶
    â”œâ”€â”€ temp/              # ä¸´æ—¶æ–‡ä»¶
    â””â”€â”€ outputs/           # è¾“å‡ºæ–‡ä»¶
```

### æºç éƒ¨ç½²

```
tranvideo/
â”œâ”€â”€ main.py                # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt       # Python ä¾èµ–
â”œâ”€â”€ config/                # é…ç½®ç›®å½•
â”‚   â”œâ”€â”€ tran-py.json       # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ prompt.txt         # ç¿»è¯‘æç¤ºè¯
â”œâ”€â”€ whisper/               # Whisper æ¨¡å‹ç›®å½•
â”‚   â””â”€â”€ large-v3-turbo.pt  # æ¨¡å‹æ–‡ä»¶ï¼ˆéœ€ä¸‹è½½ï¼‰
â”œâ”€â”€ src/                   # æºä»£ç 
â”‚   â”œâ”€â”€ api/               # API å±‚
â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ services/          # å¤–éƒ¨æœåŠ¡
â”‚   â””â”€â”€ utils/             # å·¥å…·å‡½æ•°
â”œâ”€â”€ webui/                 # Web ç•Œé¢
â”œâ”€â”€ cache/                 # ç¼“å­˜ç›®å½•
â”œâ”€â”€ db/                    # æ•°æ®åº“
â”‚   â””â”€â”€ tasks.json         # ä»»åŠ¡æ•°æ®
â””â”€â”€ logs/                  # æ—¥å¿—ç›®å½•
```

---

## å‡çº§æŒ‡å—

### Docker Compose å‡çº§

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd tranvideo

# æ‹‰å–æœ€æ–°é•œåƒ
docker compose pull

# åœæ­¢æ—§å®¹å™¨
docker compose down

# å¯åŠ¨æ–°å®¹å™¨
docker compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f tranvideo
```

### Docker å•å®¹å™¨å‡çº§

```bash
# åœæ­¢å¹¶åˆ é™¤æ—§å®¹å™¨
docker stop tranvideo
docker rm tranvideo

# æ‹‰å–æœ€æ–°é•œåƒ
docker pull kindmitaishere/tranvideo:latest

# å¯åŠ¨æ–°å®¹å™¨
docker run -d \
  --name tranvideo \
  --gpus all \
  --network host \
  --restart always \
  -p 5000:5000 \
  -v $(pwd)/cache:/root/tranvideo/cache \
  kindmitaishere/tranvideo:latest
```

### æºç éƒ¨ç½²å‡çº§

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd tranvideo

# å¤‡ä»½é…ç½®
cp config/tran-py.json config/tran-py.json.bak

# æ‹‰å–æœ€æ–°ä»£ç 
git fetch origin
git pull origin main

# æ›´æ–°ä¾èµ–
source venv/bin/activate
pip install --upgrade -r requirements.txt

# æ¢å¤é…ç½®
cp config/tran-py.json.bak config/tran-py.json

# é‡å¯æœåŠ¡
# æŒ‰ Ctrl+C åœæ­¢æ—§è¿›ç¨‹
python main.py
```

---

## å¸è½½æŒ‡å—

### Docker Compose å¸è½½

```bash
cd tranvideo

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨
docker compose down

# åˆ é™¤æ•°æ®å·ï¼ˆå¯é€‰ï¼‰
docker compose down -v

# åˆ é™¤é•œåƒï¼ˆå¯é€‰ï¼‰
docker rmi kindmitaishere/tranvideo:0.6.0
docker rmi ollama/ollama:latest

# åˆ é™¤é¡¹ç›®ç›®å½•
cd ..
rm -rf tranvideo
```

### æºç éƒ¨ç½²å¸è½½

```bash
cd tranvideo

# åœæ­¢æœåŠ¡ï¼ˆCtrl+Cï¼‰

# åˆ é™¤è™šæ‹Ÿç¯å¢ƒ
rm -rf venv

# åˆ é™¤ç¼“å­˜
rm -rf cache

# åˆ é™¤é¡¹ç›®ï¼ˆå¯é€‰ï¼‰
cd ..
rm -rf tranvideo
```

---

## æ•…éšœæ’é™¤

### GPU ä¸å¯ç”¨

```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ Docker GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi

# é‡æ–°å®‰è£… NVIDIA Container Runtime
sudo apt-get install --reinstall nvidia-container-toolkit
sudo systemctl restart docker
```

### æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# Whisper æ¨¡å‹æ›¿ä»£ä¸‹è½½åœ°å€
wget https://openaipublic.azureedge.net/main/whisper/models/large-v3-turbo.pt

# Ollama æ¨¡å‹æ‰‹åŠ¨æ‹‰å–
docker exec -it ollama ollama pull qwen3:8b

# å›½å†…é•œåƒåŠ é€Ÿ
export HF_ENDPOINT=https://hf-mirror.com
```

### ç«¯å£å†²çª

```bash
# æ£€æŸ¥ç«¯å£å ç”¨
sudo lsof -i :5000
sudo lsof -i :11434

# ä¿®æ”¹ç«¯å£ï¼ˆdocker-compose.yamlï¼‰
ports:
  - "5001:5000"  # æ”¹ä¸º 5001
```

### ç£ç›˜ç©ºé—´ä¸è¶³

```bash
# æ¸…ç† Docker
docker system prune -a

# æ¸…ç†ç¼“å­˜
rm -rf tranvideo/cache/*

# æ¸…ç†æ—¥å¿—
rm -rf tranvideo/logs/*
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨ SSD

å°†ç¼“å­˜ç›®å½•æŒ‚è½½åˆ° SSDï¼š

```yaml
volumes:
  - /path/to/ssd/cache:/root/tranvideo/cache
```

### 2. å¢åŠ å…±äº«å†…å­˜

```yaml
services:
  tranvideo:
    shm_size: 8gb
```

### 3. ä¼˜åŒ– Docker èµ„æºé™åˆ¶

```yaml
services:
  tranvideo:
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G
```

---

## ä¸‹ä¸€æ­¥

- ğŸ“– [å¿«é€Ÿå¼€å§‹](Quick-Start.md) - å¿«é€Ÿä¸Šæ‰‹æŒ‡å—
- âš™ï¸ [é…ç½®æŒ‡å—](Configuration.md) - è¯¦ç»†é…ç½®è¯´æ˜
- ğŸ”§ [API æ–‡æ¡£](API-Reference.md) - API æ¥å£æ–‡æ¡£
- ğŸ’¡ [æ•…éšœæ’é™¤](Troubleshooting.md) - å¸¸è§é—®é¢˜è§£å†³

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-24
**ç»´æŠ¤è€…**: MitaHill

[è¿”å› Wiki é¦–é¡µ](Home.md)
