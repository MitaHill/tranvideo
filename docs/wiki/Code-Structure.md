# ä»£ç ç»“æ„æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» Tranvideo çš„ä»£ç ç»„ç»‡ç»“æ„å’Œå„æ¨¡å—åŠŸèƒ½ã€‚

## ç›®å½•

- [é¡¹ç›®ç›®å½•ç»“æ„](#é¡¹ç›®ç›®å½•ç»“æ„)
- [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#æ ¸å¿ƒæ¨¡å—è¯¦è§£)
- [API è·¯ç”±æ˜ å°„](#api-è·¯ç”±æ˜ å°„)
- [æ•°æ®æ¨¡å‹](#æ•°æ®æ¨¡å‹)
- [å·¥å…·å‡½æ•°åº“](#å·¥å…·å‡½æ•°åº“)
- [å¼€å‘æŒ‡å—](#å¼€å‘æŒ‡å—)

---

## é¡¹ç›®ç›®å½•ç»“æ„

```
tranvideo/
â”œâ”€â”€ main.py                          # åº”ç”¨ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt                 # Python ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ docker-compose.yaml              # Docker Compose é…ç½®
â”œâ”€â”€ Dockerfile                       # Docker é•œåƒæ„å»ºæ–‡ä»¶
â”œâ”€â”€ .gitignore                       # Git å¿½ç•¥è§„åˆ™
â”œâ”€â”€ README.md                        # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ LICENSE                          # MIT è®¸å¯è¯
â”‚
â”œâ”€â”€ config/                          # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ tran-py.json                 # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ prompt.txt                   # ç¿»è¯‘æç¤ºè¯
â”‚
â”œâ”€â”€ src/                             # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ api/                         # API å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py              # è·¯ç”±å®šä¹‰ (20+ ç«¯ç‚¹)
â”‚   â”‚   â”œâ”€â”€ handlers.py              # è¯·æ±‚å¤„ç†å™¨
â”‚   â”‚   â”œâ”€â”€ security.py              # å®‰å…¨ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ security_modules/        # å®‰å…¨æ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ file_type_verification.py  # æ–‡ä»¶ç±»å‹éªŒè¯
â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limiting.py           # é€Ÿç‡é™åˆ¶
â”‚   â”‚   â”‚   â””â”€â”€ IP_banned.py               # IP é»‘åå•
â”‚   â”‚   â””â”€â”€ prog_bar/                # è¿›åº¦è·Ÿè¸ª
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ progress_tracker.py  # è¿›åº¦è¿½è¸ªå™¨
â”‚   â”‚       â””â”€â”€ progress_manager.py  # è¿›åº¦ç®¡ç†å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ task.py                  # ä»»åŠ¡å¤„ç†å™¨ (æ ¸å¿ƒ)
â”‚   â”‚   â”œâ”€â”€ batch.py                 # æ‰¹é‡å¤„ç†ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ video.py                 # è§†é¢‘æ“ä½œå°è£…
â”‚   â”‚   â”œâ”€â”€ invite.py                # é‚€è¯·ç éªŒè¯
â”‚   â”‚   â”œâ”€â”€ coordinate.py            # ä»»åŠ¡åè°ƒå™¨
â”‚   â”‚   â””â”€â”€ coordinate_models/       # æ•°æ®åº“æ¨¡å‹
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ database_handler.py  # æ•°æ®åº“I/O
â”‚   â”‚       â”œâ”€â”€ task_manager.py      # ä»»åŠ¡ç®¡ç†å™¨
â”‚   â”‚       â”œâ”€â”€ batch_manager.py     # æ‰¹æ¬¡ç®¡ç†å™¨
â”‚   â”‚       â””â”€â”€ cleanup_manager.py   # ç¼“å­˜æ¸…ç†å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                    # å¤–éƒ¨æœåŠ¡æ¥å£
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ use_whisper.py           # Whisper æœåŠ¡æ¥å£
â”‚   â”‚   â”œâ”€â”€ whisper_direct.py        # Whisper ç›´æ¥è°ƒç”¨
â”‚   â”‚   â”œâ”€â”€ whisper_service.py       # Whisper æœåŠ¡ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ tran.py                  # ç¿»è¯‘æœåŠ¡ (Ollama/OpenAI)
â”‚   â”‚   â””â”€â”€ enabled.py               # å¯åŠ¨æ—¶ä»»åŠ¡æ¢å¤
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # å·¥å…·å‡½æ•°åº“
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ vram_manager.py          # GPU æ˜¾å­˜ç®¡ç† (æ ¸å¿ƒ)
â”‚       â”œâ”€â”€ webui.py                 # Web UI è·¯ç”±
â”‚       â”œâ”€â”€ logger.py                # æ—¥å¿—ç³»ç»Ÿ
â”‚       â”œâ”€â”€ filer.py                 # æ–‡ä»¶æ“ä½œå·¥å…·
â”‚       â”œâ”€â”€ bilingual_subtitle.py    # åŒè¯­å­—å¹•ç”Ÿæˆ
â”‚       â”œâ”€â”€ audio_preprocessor.py    # éŸ³é¢‘é¢„å¤„ç†
â”‚       â”œâ”€â”€ done_timeout_delete.py   # å®šæ—¶æ¸…ç†
â”‚       â””â”€â”€ tq.py                    # é˜Ÿåˆ—ç®¡ç†
â”‚
â”œâ”€â”€ webui/                           # å‰ç«¯ç•Œé¢
â”‚   â”œâ”€â”€ index.html                   # ä¸»é¡µé¢
â”‚   â”œâ”€â”€ api-docs.html                # API æ–‡æ¡£é¡µé¢
â”‚   â”œâ”€â”€ faq.html                     # FAQ é¡µé¢
â”‚   â”œâ”€â”€ css/                         # æ ·å¼è¡¨
â”‚   â”‚   â””â”€â”€ style.css
â”‚   â”œâ”€â”€ js/                          # JavaScript
â”‚   â”‚   â”œâ”€â”€ main.js                  # ä¸»é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ upload.js                # ä¸Šä¼ å¤„ç†
â”‚   â”‚   â””â”€â”€ progress.js              # è¿›åº¦æ˜¾ç¤º
â”‚   â””â”€â”€ images/                      # å›¾ç‰‡èµ„æº
â”‚
â”œâ”€â”€ docs/                            # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ wiki/                        # Wiki æ–‡æ¡£
â”‚   â”‚   â”œâ”€â”€ Home.md
â”‚   â”‚   â”œâ”€â”€ Quick-Start.md
â”‚   â”‚   â”œâ”€â”€ API-Reference.md
â”‚   â”‚   â”œâ”€â”€ Installation.md
â”‚   â”‚   â”œâ”€â”€ Basic-Usage.md
â”‚   â”‚   â”œâ”€â”€ Batch-Processing.md
â”‚   â”‚   â”œâ”€â”€ Configuration.md
â”‚   â”‚   â”œâ”€â”€ Troubleshooting.md
â”‚   â”‚   â”œâ”€â”€ Architecture.md
â”‚   â”‚   â”œâ”€â”€ Code-Structure.md
â”‚   â”‚   â””â”€â”€ VRAM-Management.md
â”‚   â”œâ”€â”€ CONTRIBUTING.md              # è´¡çŒ®æŒ‡å—
â”‚   â”œâ”€â”€ RELEASE_GUIDE.md             # å‘å¸ƒæŒ‡å—
â”‚   â””â”€â”€ VERSION_POLICY.md            # ç‰ˆæœ¬ç­–ç•¥
â”‚
â”œâ”€â”€ cache/                           # ç¼“å­˜ç›®å½• (è¿è¡Œæ—¶ç”Ÿæˆ)
â”‚   â”œâ”€â”€ uploads/                     # ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶
â”‚   â”œâ”€â”€ temp/                        # ä¸´æ—¶å¤„ç†æ–‡ä»¶
â”‚   â””â”€â”€ outputs/                     # è¾“å‡ºæ–‡ä»¶
â”‚
â”œâ”€â”€ db/                              # æ•°æ®åº“ç›®å½•
â”‚   â””â”€â”€ tasks.json                   # ä»»åŠ¡æ•°æ®åº“ (JSON)
â”‚
â”œâ”€â”€ logs/                            # æ—¥å¿—ç›®å½•
â”‚   â””â”€â”€ tranvideo.log                # åº”ç”¨æ—¥å¿—
â”‚
â””â”€â”€ whisper/                         # Whisper æ¨¡å‹ç›®å½•
    â””â”€â”€ large-v3-turbo.pt            # æ¨¡å‹æ–‡ä»¶ (éœ€ä¸‹è½½)
```

---

## æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. main.py

**åŠŸèƒ½**: åº”ç”¨ç¨‹åºå…¥å£ï¼ŒFlask åº”ç”¨åˆå§‹åŒ–

**å…³é”®ä»£ç **:

```python
from flask import Flask
from src.api import init_routes
from src.services.enabled import recovery_tasks
from src.utils.vram_manager import init_vram_manager

app = Flask(__name__)

# åˆå§‹åŒ–è·¯ç”±
init_routes(app)

# å¯åŠ¨æ—¶æ¢å¤æœªå®Œæˆä»»åŠ¡
recovery_tasks()

# åˆå§‹åŒ– VRAM ç®¡ç†å™¨
init_vram_manager()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

**æµç¨‹**:
1. åˆ›å»º Flask åº”ç”¨
2. æ³¨å†Œ API è·¯ç”±
3. æ¢å¤æœªå®Œæˆä»»åŠ¡
4. åˆå§‹åŒ– VRAM ç®¡ç†
5. å¯åŠ¨æœåŠ¡å™¨

---

### 2. src/api/

#### __init__.py - è·¯ç”±å®šä¹‰

**åŠŸèƒ½**: å®šä¹‰æ‰€æœ‰ API ç«¯ç‚¹

**è·¯ç”±åˆ†ç±»**:

```python
def init_routes(app):
    # å¥åº·æ£€æŸ¥
    app.route('/api/whisper/health')(health_check)
    app.route('/api/status')(system_status)

    # é…ç½®ç®¡ç†
    app.route('/api/tranpy/config')(get_config)
    app.route('/api/tranpy/config-ollama-api/<api_url>')(config_ollama_api)
    # ... æ›´å¤šé…ç½®è·¯ç”±

    # è§†é¢‘å¤„ç†
    app.route('/api/process/srt/<invite_code>', methods=['POST'])(process_srt)
    app.route('/api/process/video/<invite_code>', methods=['POST'])(process_video)

    # æ‰¹é‡å¤„ç†
    app.route('/api/batch/process/<invite_code>', methods=['POST'])(batch_process)
    app.route('/api/batch/<batch_id>')(get_batch_status)
    app.route('/api/batch/download/<batch_id>')(download_batch)

    # ä»»åŠ¡æŸ¥è¯¢
    app.route('/api/task/<task_id>')(get_task_status)
    app.route('/api/query/<task_id>')(query_task)

    # æ–‡ä»¶ä¸‹è½½
    app.route('/api/download/srt/<filename>')(download_srt)
    app.route('/api/download/video/<filename>')(download_video)

    # Web UI
    app.route('/')(index)
    app.route('/api-docs.html')(api_docs)
    app.route('/faq.html')(faq)
```

#### handlers.py - è¯·æ±‚å¤„ç†å™¨

**å…³é”®å‡½æ•°**:

```python
def process_srt(invite_code):
    """å¤„ç†è§†é¢‘ç”Ÿæˆå­—å¹•"""
    # 1. éªŒè¯é‚€è¯·ç 
    if not validate_invite_code(invite_code):
        return error_response('Invalid invite code')

    # 2. è·å–ä¸Šä¼ æ–‡ä»¶
    file = request.files.get('file')
    if not file:
        return error_response('No file uploaded')

    # 3. å®‰å…¨éªŒè¯
    if not security_check(file, request.remote_addr):
        return error_response('Security check failed')

    # 4. ä¿å­˜æ–‡ä»¶
    task_id = generate_task_id()
    file_path = save_upload_file(file, task_id)

    # 5. åˆ›å»ºä»»åŠ¡
    task = create_task(
        task_id=task_id,
        file_path=file_path,
        mode='srt',
        invite_code=invite_code
    )

    # 6. åŠ å…¥é˜Ÿåˆ—
    task_queue.add(task_id)

    # 7. è¿”å›ç»“æœ
    return success_response({
        'task_id': task_id,
        'video_name': file.filename,
        'estimated_time': calculate_estimate(file_path)
    })
```

#### security.py - å®‰å…¨ç®¡ç†å™¨

**åŠŸèƒ½**: ç»Ÿä¸€å®‰å…¨éªŒè¯å…¥å£

```python
class SecurityManager:
    def __init__(self):
        self.file_verifier = FileTypeVerification()
        self.rate_limiter = RateLimiting()
        self.ip_filter = IPBanned()

    def check(self, file, ip_address):
        """æ‰§è¡Œæ‰€æœ‰å®‰å…¨æ£€æŸ¥"""
        # 1. IP é»‘åå•æ£€æŸ¥
        if self.ip_filter.is_banned(ip_address):
            return False, 'IP banned'

        # 2. é€Ÿç‡é™åˆ¶æ£€æŸ¥
        if not self.rate_limiter.check(ip_address):
            return False, 'Rate limit exceeded'

        # 3. æ–‡ä»¶ç±»å‹éªŒè¯
        if not self.file_verifier.verify(file):
            return False, 'Invalid file type'

        return True, 'OK'
```

---

### 3. src/core/

#### task.py - ä»»åŠ¡å¤„ç†å™¨

**åŠŸèƒ½**: å•ä»»åŠ¡çš„å®Œæ•´å¤„ç†æµç¨‹

**æ ¸å¿ƒå‡½æ•°**:

```python
class TaskProcessor:
    def process(self, task_id):
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task = db.get_task(task_id)

        try:
            # 1. æ›´æ–°çŠ¶æ€: processing
            update_status(task_id, 'processing', 0)

            # 2. æå–éŸ³é¢‘
            audio_path = extract_audio(task['video_path'])
            update_status(task_id, 'æå–åŸæ–‡å­—å¹•', 10)

            # 3. è¯­éŸ³è¯†åˆ«
            raw_srt = whisper_transcribe(audio_path)
            update_status(task_id, 'æå–åŸæ–‡å­—å¹•', 50)

            # 4. ç”Ÿæˆå­—å¹•æ–‡ä»¶
            save_srt(task_id, raw_srt, 'raw')

            # 5. ç¿»è¯‘
            update_status(task_id, 'ç¿»è¯‘åŸæ–‡å­—å¹•', 50)
            translated_srt = translate(raw_srt)
            save_srt(task_id, translated_srt, 'translated')

            # 6. åŒè¯­å­—å¹•
            bilingual_srt = merge_bilingual(raw_srt, translated_srt)
            save_srt(task_id, bilingual_srt, 'bilingual')
            update_status(task_id, 'ç¿»è¯‘åŸæ–‡å­—å¹•', 90)

            # 7. è§†é¢‘åˆæˆ (å¯é€‰)
            if task['mode'] == 'video':
                update_status(task_id, 'åˆæˆè§†é¢‘', 90)
                merge_video(task_id)

            # 8. å®Œæˆ
            update_status(task_id, 'å·²å®Œæˆ', 100)

        except Exception as e:
            update_status(task_id, 'å¤±è´¥', 0, error=str(e))
            logger.error(f"Task {task_id} failed: {e}")

def extract_audio(video_path):
    """æå–éŸ³é¢‘"""
    output_path = video_path.replace('.mp4', '.wav')
    cmd = [
        'ffmpeg', '-i', video_path,
        '-vn', '-acodec', 'pcm_s16le',
        '-ar', '16000', '-ac', '1',
        output_path
    ]
    subprocess.run(cmd, check=True)
    return output_path

def whisper_transcribe(audio_path):
    """Whisper è¯­éŸ³è¯†åˆ«"""
    whisper_service = WhisperService()
    result = whisper_service.transcribe(audio_path)
    return result_to_srt(result)

def translate(srt_content):
    """ç¿»è¯‘ SRT å­—å¹•"""
    translator = get_translator()
    translated_lines = []

    for subtitle in parse_srt(srt_content):
        translated_text = translator.translate(subtitle.text)
        subtitle.text = translated_text
        translated_lines.append(subtitle)

    return format_srt(translated_lines)
```

#### batch.py - æ‰¹é‡å¤„ç†

**åŠŸèƒ½**: æ‰¹é‡ä»»åŠ¡ç®¡ç†

```python
class BatchProcessor:
    def create_batch(self, files, mode, invite_code):
        """åˆ›å»ºæ‰¹é‡ä»»åŠ¡"""
        batch_id = generate_batch_id()
        task_ids = []

        # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºä»»åŠ¡
        for file in files:
            task_id = generate_task_id()

            # ä¿å­˜æ–‡ä»¶
            file_path = save_upload_file(file, task_id)

            # åˆ›å»ºä»»åŠ¡
            task = create_task(
                task_id=task_id,
                file_path=file_path,
                mode=mode,
                batch_id=batch_id,
                invite_code=invite_code
            )

            task_ids.append(task_id)

            # åŠ å…¥é˜Ÿåˆ—
            task_queue.add(task_id)

        # åˆ›å»ºæ‰¹æ¬¡è®°å½•
        batch = {
            'batch_id': batch_id,
            'task_ids': task_ids,
            'status': 'é˜Ÿåˆ—ä¸­',
            'created_at': datetime.now()
        }

        db.save_batch(batch)

        return batch_id, task_ids
```

#### coordinate.py - ä»»åŠ¡åè°ƒå™¨

**åŠŸèƒ½**: é˜Ÿåˆ—ç®¡ç†å’Œä»»åŠ¡è°ƒåº¦

```python
class TaskCoordinator:
    def __init__(self):
        self.queue = Queue()
        self.current_task = None
        self.running = False

    def start(self):
        """å¯åŠ¨åè°ƒå™¨"""
        self.running = True
        threading.Thread(target=self._process_loop, daemon=True).start()

    def add_task(self, task_id):
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        self.queue.put(task_id)
        db.update_task_status(task_id, 'é˜Ÿåˆ—ä¸­')

    def _process_loop(self):
        """ä»»åŠ¡å¤„ç†å¾ªç¯"""
        while self.running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
                task_id = self.queue.get(timeout=1)

                # è®°å½•å½“å‰ä»»åŠ¡
                self.current_task = task_id

                # å¤„ç†ä»»åŠ¡
                processor = TaskProcessor()
                processor.process(task_id)

                # æ¸…ç©ºå½“å‰ä»»åŠ¡
                self.current_task = None

            except Empty:
                time.sleep(1)
            except Exception as e:
                logger.error(f"Error processing task: {e}")
```

---

### 4. src/services/

#### use_whisper.py - Whisper æœåŠ¡

**åŠŸèƒ½**: Whisper æ¨¡å‹å°è£…

```python
class WhisperService:
    _instance = None

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        # åŠ è½½æ¨¡å‹
        self.model = whisper.load_model(
            "large-v3-turbo",
            device="cuda",
            download_root="./whisper"
        )

        self._initialized = True

    def transcribe(self, audio_path, language=None):
        """è¯­éŸ³è¯†åˆ«"""
        result = self.model.transcribe(
            audio_path,
            language=language,
            task="transcribe",
            fp16=True,  # ä½¿ç”¨ FP16 åŠ é€Ÿ
            verbose=False
        )

        return result

    def to(self, device):
        """ç§»åŠ¨æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡"""
        self.model.to(device)

    def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        return {
            'status': 'healthy',
            'model': 'large-v3-turbo',
            'device': str(self.model.device)
        }
```

#### tran.py - ç¿»è¯‘æœåŠ¡

**åŠŸèƒ½**: å¤šåç«¯ç¿»è¯‘æœåŠ¡

```python
class TranslationService:
    def __init__(self):
        self.config = load_config()

    def translate(self, text):
        """ç¿»è¯‘æ–‡æœ¬"""
        translator_type = self.config['translator_type']

        if translator_type == 'ollama':
            return self._ollama_translate(text)
        elif translator_type == 'openai':
            return self._openai_translate(text)
        else:
            raise ValueError(f"Unknown translator: {translator_type}")

    def _ollama_translate(self, text):
        """ä½¿ç”¨ Ollama ç¿»è¯‘"""
        url = f"{self.config['ollama_api']}/api/generate"

        payload = {
            'model': self.config['ollama_model'],
            'prompt': self._build_prompt(text),
            'stream': False
        }

        response = requests.post(url, json=payload)
        result = response.json()

        return self._extract_translation(result['response'])

    def _openai_translate(self, text):
        """ä½¿ç”¨ OpenAI ç¿»è¯‘"""
        url = f"{self.config['openai_base_url']}/chat/completions"

        headers = {
            'Authorization': f"Bearer {self.config['openai_api_key']}",
            'Content-Type': 'application/json'
        }

        payload = {
            'model': self.config['openai_model'],
            'messages': [
                {'role': 'system', 'content': load_prompt()},
                {'role': 'user', 'content': text}
            ]
        }

        response = requests.post(url, json=payload, headers=headers)
        result = response.json()

        return self._extract_translation(result['choices'][0]['message']['content'])

    def _build_prompt(self, text):
        """æ„å»ºæç¤ºè¯"""
        system_prompt = load_prompt()
        return f"{system_prompt}\n\n{text}"

    def _extract_translation(self, response):
        """æå–ç¿»è¯‘ç»“æœ"""
        # æå–ä»£ç å—ä¸­çš„å†…å®¹
        match = re.search(r'```\n(.*?)\n```', response, re.DOTALL)
        if match:
            return match.group(1).strip()
        return response.strip()
```

---

### 5. src/utils/

#### vram_manager.py - VRAM ç®¡ç†å™¨

**åŠŸèƒ½**: GPU æ˜¾å­˜æ™ºèƒ½è°ƒåº¦

```python
class VRAMManager:
    def __init__(self):
        self.whisper_on_gpu = True
        self.ollama_loaded = False
        self.config = load_config()

    def is_polling_enabled(self):
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨æ˜¾å­˜è½®è¯¢"""
        return (
            self.config['translator_type'] == 'ollama' and
            '127.0.0.1' in self.config['ollama_api']
        )

    def switch_to_translation_mode(self):
        """åˆ‡æ¢åˆ°ç¿»è¯‘æ¨¡å¼"""
        if not self.is_polling_enabled():
            return

        logger.info("Switching to translation mode...")

        # 1. Whisper ç§»è‡³ CPU
        whisper_service = WhisperService()
        whisper_service.to('cpu')
        self.whisper_on_gpu = False

        # 2. æ¸…ç† GPU ç¼“å­˜
        torch.cuda.empty_cache()
        gc.collect()

        time.sleep(2)  # ç­‰å¾…ç¼“å­˜æ¸…ç†

        # 3. åŠ è½½ Ollama åˆ° GPU
        self._load_ollama_to_gpu()
        self.ollama_loaded = True

        logger.info("Translation mode activated")

    def switch_to_transcription_mode(self):
        """åˆ‡æ¢åˆ°è½¬å½•æ¨¡å¼"""
        if not self.is_polling_enabled():
            return

        logger.info("Switching to transcription mode...")

        # 1. å¸è½½ Ollama
        self._unload_ollama()
        self.ollama_loaded = False

        # 2. æ¸…ç† GPU ç¼“å­˜
        torch.cuda.empty_cache()
        gc.collect()

        time.sleep(2)

        # 3. Whisper ç§»è‡³ GPU
        whisper_service = WhisperService()
        whisper_service.to('cuda')
        self.whisper_on_gpu = True

        logger.info("Transcription mode activated")

    def _load_ollama_to_gpu(self):
        """åŠ è½½ Ollama åˆ° GPU"""
        url = f"{self.config['ollama_api']}/api/generate"

        # é¢„çƒ­æ¨¡å‹ï¼ˆè§¦å‘åŠ è½½åˆ° GPUï¼‰
        payload = {
            'model': self.config['ollama_model'],
            'prompt': 'Hello',
            'stream': False
        }

        requests.post(url, json=payload)

    def _unload_ollama(self):
        """å¸è½½ Ollama æ¨¡å‹"""
        url = f"{self.config['ollama_api']}/api/unload"

        payload = {
            'model': self.config['ollama_model']
        }

        requests.post(url, json=payload)

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.ollama_loaded:
            self._unload_ollama()

        if not self.whisper_on_gpu:
            whisper_service = WhisperService()
            whisper_service.to('cuda')

        torch.cuda.empty_cache()
        gc.collect()
```

---

## API è·¯ç”±æ˜ å°„

| è·¯å¾„ | æ–¹æ³• | å¤„ç†å™¨ | åŠŸèƒ½ |
|------|------|--------|------|
| `/api/whisper/health` | GET | `health_check()` | Whisper å¥åº·æ£€æŸ¥ |
| `/api/status` | GET | `system_status()` | ç³»ç»ŸçŠ¶æ€ |
| `/api/tranpy/config` | GET | `get_config()` | è·å–é…ç½® |
| `/api/tranpy/config-ollama-api/<api_url>` | GET | `config_ollama_api()` | é…ç½® Ollama API |
| `/api/process/srt/<invite_code>` | POST | `process_srt()` | å¤„ç†è§†é¢‘ï¼ˆå­—å¹•ï¼‰ |
| `/api/process/video/<invite_code>` | POST | `process_video()` | å¤„ç†è§†é¢‘ï¼ˆè§†é¢‘ï¼‰ |
| `/api/batch/process/<invite_code>` | POST | `batch_process()` | æ‰¹é‡å¤„ç† |
| `/api/batch/<batch_id>` | GET | `get_batch_status()` | æ‰¹æ¬¡çŠ¶æ€ |
| `/api/task/<task_id>` | GET | `get_task_status()` | ä»»åŠ¡çŠ¶æ€ |
| `/api/download/srt/<filename>` | GET | `download_srt()` | ä¸‹è½½å­—å¹• |
| `/api/download/video/<filename>` | GET | `download_video()` | ä¸‹è½½è§†é¢‘ |

å®Œæ•´è·¯ç”±åˆ—è¡¨è§ [API å‚è€ƒæ–‡æ¡£](API-Reference.md)ã€‚

---

## æ•°æ®æ¨¡å‹

### ä»»åŠ¡æ¨¡å‹ (Task)

```python
{
    "task_id": str,              # å”¯ä¸€æ ‡è¯†
    "video_path": str,           # è§†é¢‘æ–‡ä»¶è·¯å¾„
    "video_name": str,           # åŸå§‹æ–‡ä»¶å
    "video_duration": float,     # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    "mode": str,                 # "srt" æˆ– "video"
    "status": str,               # ä»»åŠ¡çŠ¶æ€
    "progress": str,             # è¿›åº¦æè¿°
    "current_step": str,         # å½“å‰æ­¥éª¤
    "prog_bar": int,             # è¿›åº¦ç™¾åˆ†æ¯” (0-100)
    "batch_id": str | None,      # æ‰€å±æ‰¹æ¬¡ï¼ˆå¯ä¸ºç©ºï¼‰
    "invite_code": str,          # é‚€è¯·ç 
    "created_at": str,           # åˆ›å»ºæ—¶é—´
    "updated_at": str,           # æ›´æ–°æ—¶é—´
    "downloaded": bool,          # æ˜¯å¦å·²ä¸‹è½½
    "expired": bool,             # æ˜¯å¦å·²è¿‡æœŸ
    "error": str | None,         # é”™è¯¯ä¿¡æ¯
    "resume_data": dict          # æ¢å¤æ•°æ®
}
```

### æ‰¹æ¬¡æ¨¡å‹ (Batch)

```python
{
    "batch_id": str,             # æ‰¹æ¬¡ID
    "sub_tasks": dict,           # å­ä»»åŠ¡å­—å…¸
    "status": str,               # æ‰¹æ¬¡çŠ¶æ€
    "progress": str,             # è¿›åº¦æè¿°
    "created_at": str,           # åˆ›å»ºæ—¶é—´
    "updated_at": str            # æ›´æ–°æ—¶é—´
}
```

### é…ç½®æ¨¡å‹ (Config)

```python
{
    "translator_type": str,      # "ollama" æˆ– "openai"
    "ollama_api": str,           # Ollama API åœ°å€
    "ollama_model": str,         # Ollama æ¨¡å‹åç§°
    "openai_base_url": str,      # OpenAI Base URL
    "openai_api_key": str,       # OpenAI API Key
    "openai_model": str          # OpenAI æ¨¡å‹åç§°
}
```

---

## å·¥å…·å‡½æ•°åº“

### filer.py - æ–‡ä»¶æ“ä½œ

```python
def save_upload_file(file, task_id):
    """ä¿å­˜ä¸Šä¼ æ–‡ä»¶"""
    filename = secure_filename(file.filename)
    ext = os.path.splitext(filename)[1]
    save_path = f"cache/uploads/{task_id}{ext}"

    file.save(save_path)
    return save_path

def get_video_duration(video_path):
    """è·å–è§†é¢‘æ—¶é•¿"""
    cmd = [
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        video_path
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    return float(result.stdout.strip())
```

### logger.py - æ—¥å¿—ç³»ç»Ÿ

```python
import logging
from logging.handlers import RotatingFileHandler

def setup_logger():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logger = logging.getLogger('tranvideo')
    logger.setLevel(logging.INFO)

    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = RotatingFileHandler(
        'logs/tranvideo.log',
        maxBytes=2*1024*1024,  # 2MB
        backupCount=5
    )

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()

    # æ ¼å¼åŒ–
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger
```

---

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„ API ç«¯ç‚¹

1. **åœ¨ `src/api/__init__.py` ä¸­æ³¨å†Œè·¯ç”±**:

```python
app.route('/api/new-endpoint')(new_endpoint_handler)
```

2. **åœ¨ `src/api/handlers.py` ä¸­å®ç°å¤„ç†å™¨**:

```python
def new_endpoint_handler():
    # å¤„ç†é€»è¾‘
    return jsonify({'success': True})
```

### æ·»åŠ æ–°çš„ç¿»è¯‘å™¨

1. **åˆ›å»ºç¿»è¯‘å™¨ç±»** (ç»§æ‰¿åŸºç±»):

```python
class CustomTranslator(BaseTranslator):
    def translate(self, text):
        # å®ç°ç¿»è¯‘é€»è¾‘
        return translated_text
```

2. **æ³¨å†Œåˆ°å·¥å‚**:

```python
# åœ¨ tran.py ä¸­
TRANSLATORS = {
    'ollama': OllamaTranslator,
    'openai': OpenAITranslator,
    'custom': CustomTranslator  # æ–°å¢
}
```

### ä¿®æ”¹æ˜¾å­˜ç®¡ç†ç­–ç•¥

ç¼–è¾‘ `src/utils/vram_manager.py`ï¼š

```python
class VRAMManager:
    # ä¿®æ”¹å‚æ•°
    WHISPER_MEMORY_FRACTION = 0.85  # é™ä½ Whisper æ˜¾å­˜å ç”¨
    SWITCH_DELAY = 3                 # å¢åŠ åˆ‡æ¢å»¶è¿Ÿ
```

---

## ä»£ç è§„èŒƒ

### Python é£æ ¼

- **PEP 8** ç¼–ç è§„èŒƒ
- **ç±»å‹æ³¨è§£**: ä½¿ç”¨ Type Hints
- **æ–‡æ¡£å­—ç¬¦ä¸²**: æ‰€æœ‰å‡½æ•°éœ€è¦ docstring

### å‘½åçº¦å®š

- **å˜é‡**: `snake_case`
- **å‡½æ•°**: `snake_case`
- **ç±»**: `PascalCase`
- **å¸¸é‡**: `UPPER_SNAKE_CASE`

### ç¤ºä¾‹

```python
from typing import Dict, List, Optional

class TaskProcessor:
    """ä»»åŠ¡å¤„ç†å™¨

    å¤„ç†å•ä¸ªè§†é¢‘ç¿»è¯‘ä»»åŠ¡çš„å®Œæ•´æµç¨‹ã€‚
    """

    MAX_RETRIES: int = 3

    def __init__(self, task_id: str):
        """åˆå§‹åŒ–å¤„ç†å™¨

        Args:
            task_id: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
        """
        self.task_id = task_id
        self.retry_count = 0

    def process(self) -> Dict[str, any]:
        """å¤„ç†ä»»åŠ¡

        Returns:
            åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸

        Raises:
            ProcessingError: å¤„ç†å¤±è´¥æ—¶æŠ›å‡º
        """
        # å®ç°...
        pass
```

---

## æµ‹è¯•

### å•å…ƒæµ‹è¯•

```python
# tests/test_task.py
import unittest
from src.core.task import TaskProcessor

class TestTaskProcessor(unittest.TestCase):
    def test_extract_audio(self):
        processor = TaskProcessor('test_task')
        audio_path = processor.extract_audio('test_video.mp4')
        self.assertTrue(os.path.exists(audio_path))
```

### è¿è¡Œæµ‹è¯•

```bash
python -m pytest tests/
```

---

## ç›¸å…³æ–‡æ¡£

- ğŸ“– [æ¶æ„æ–‡æ¡£](Architecture.md) - ç³»ç»Ÿæ¶æ„è®¾è®¡
- ğŸ”§ [API æ–‡æ¡£](API-Reference.md) - API æ¥å£è¯¦æƒ…
- âš™ï¸ [é…ç½®æŒ‡å—](Configuration.md) - é…ç½®è¯´æ˜
- ğŸ’¡ [æ•…éšœæ’é™¤](Troubleshooting.md) - é—®é¢˜è§£å†³

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-24
**ç»´æŠ¤è€…**: MitaHill

[è¿”å› Wiki é¦–é¡µ](Home.md)
